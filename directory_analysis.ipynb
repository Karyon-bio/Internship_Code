{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMUhyRNWZDCZ"
   },
   "source": [
    "# Notebook Purpose\n",
    "1. Take in the current directory & file structure where the notebook is being run\n",
    "\n",
    "2. ChatGPT Nano analyzes the current structure and offers an impoved file structure for readability, and formating standards\n",
    "\n",
    "3. Outputs are parsed as a rubric on a 10 point scale and a theoretical new directory structure with previous names found in parentheses on the same line\n",
    "\n",
    "4. A secondary output is also made in the form of a custom JSON formats for both outputs independently & together  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udoX-wIgwKMS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import re\n",
    "import json\n",
    "### Need to add api key to function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cEgWiGHz7hAS"
   },
   "outputs": [],
   "source": [
    "def directory_tree_json():\n",
    "    \"\"\"\n",
    "    Generates a directory tree starting from the specified path\n",
    "    and returns it as a dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    directory_tree = {}\n",
    "    home_path = os.getcwd()\n",
    "    base_name = os.path.basename(home_path)\n",
    "\n",
    "    for root, dirs, files in os.walk(home_path):\n",
    "        # Build the tree structure\n",
    "        sub_tree = {\"folders\": dirs, \"files\": files}\n",
    "        directory_tree[home_path] = sub_tree\n",
    "\n",
    "    with open(f'directory_{base_name}.json', \"w\") as json_file:\n",
    "        json.dump(directory_tree, json_file, indent=4)\n",
    "\n",
    "directory_tree_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80ZRenIz0R9x",
    "outputId": "4cbbc059-9ae8-41af-f5cb-2c32e4a15d94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/content': {'folders': [], 'files': ['anscombe.json', 'README.md', 'california_housing_train.csv', 'mnist_train_small.csv', 'california_housing_test.csv', 'mnist_test.csv']}}\n",
      "{\n",
      "    \"graded_content\": {\n",
      "        \"Kedro_Organization_Standards\": {\n",
      "            \"grade\": 40,\n",
      "            \"reasons\": [\n",
      "                \"All files are placed directly under the '/content' directory, lacking appropriate separation into 'data' and 'notebooks' directories.\",\n",
      "                \"The absence of modular structure makes it difficult to distinguish between data files and project documentation.\"\n",
      "            ],\n",
      "            \"improvements\": \"Create dedicated directories such as 'data', 'notebooks', and 'src' to enhance organization.\"\n",
      "        },\n",
      "        \"Kedro_Naming_Standards\": {\n",
      "            \"grade\": 70,\n",
      "            \"reasons\": [\n",
      "                \"The filenames are descriptive but do not adhere to a consistent naming convention (e.g., 'anscombe.json' could be clearer with context).\",\n",
      "                \"File extensions are appropriate but should ensure uniformity across all files.\"\n",
      "            ],\n",
      "            \"improvements\": \"Standardize naming conventions for files to include contextual prefixes or suffixes for clarity.\"\n",
      "        },\n",
      "        \"Packaging_Standards\": {\n",
      "            \"grade\": 50,\n",
      "            \"reasons\": [\n",
      "                \"No clear packaging structure is evident, making it challenging to understand dependencies or module functionalities.\",\n",
      "                \"Lack of a setup file or requirements documentation for dependencies.\"\n",
      "            ],\n",
      "            \"improvements\": \"Implement a package structure with __init__.py files and create a setup.py for managing dependencies.\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "output break\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def review_directory():\n",
    "\n",
    "  home_path = os.getcwd()\n",
    "  base_name = os.path.basename(home_path)\n",
    "  tree_file = \"directory_\" + base_name + '.json'\n",
    "  client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "  with open(tree_file, 'r') as newfile:\n",
    "    directory_tree_file = json.load(newfile)\n",
    "    directory_dump = json.dumps(directory_tree_file)\n",
    "  print(directory_tree_file)\n",
    "  prompt = f\"\"\"\n",
    "             Review the given Directory tree json file dictionary and grade it on the parameters given:\n",
    "             1. Kedro Organization standards\n",
    "             2. Kedro Naming standards\n",
    "             3. If applicable, Packaging standards\n",
    "             The Output should be the following:\n",
    "             1. Return only valid JSON\n",
    "             2. Contain a grade for each aspect out of 100 with 2 bullet points for the reasonings for the grades and how to improve the directory tree\n",
    "             3. The format should follow the structure of the example format:\n",
    "             example format:\n",
    "             '{{\n",
    "                 \"graded_content\": {{\n",
    "                     \"Kedro_Organization_Standards\": {{\n",
    "                         \"grade\": 60,\n",
    "                         \"reasons\": [\n",
    "                             \"All data files are in the root directory, lacking necessary separation into 'data' and 'notebooks' folders.\",\n",
    "                             \"No clear structure following Kedro's modular design principles, which can complicate pipeline management.\"\n",
    "                             ],\n",
    "                         \"improvements\": \"Create separate directories for 'data', 'src', and 'notebooks'.\"\n",
    "                         }}\n",
    "                 }}\n",
    "             }}'\n",
    "\n",
    "            '''\n",
    "            {directory_tree_file}\n",
    "            '''\n",
    "\n",
    "          \"\"\"\n",
    "\n",
    "  try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                      {'role' : 'system', 'content' : 'You are a Data pipeline engineer designing a repository, dont be verbose'},\n",
    "                      {\"role\": \"user\", \"content\": prompt}\n",
    "                     ],\n",
    "            max_tokens=500\n",
    "        )\n",
    "        output = response.choices[0].message.content\n",
    "\n",
    "        print(output)\n",
    "        print('output break')\n",
    "        clean_output = output.strip()\n",
    "        clean_json_str = \"\".join(line.strip() for line in clean_output.splitlines())\n",
    "\n",
    "        parsed_json0 = json.loads(clean_json_str)\n",
    "        # Save to JSON file\n",
    "        with open(f'graded_{base_name}.json', 'w') as json_file:\n",
    "            json.dump(parsed_json0, json_file, indent=4)\n",
    "\n",
    "  except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "review_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ja-flIOE0gtt",
    "outputId": "096f3b57-759c-433c-af52-6c9a3cbe0df0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/content': {'folders': [], 'files': ['anscombe.json', 'README.md', 'california_housing_train.csv', 'mnist_train_small.csv', 'california_housing_test.csv', 'mnist_test.csv']}}\n",
      "```json\n",
      "{\n",
      "    \"/content\": {\n",
      "        \"folders\": [],\n",
      "        \"files\": [\n",
      "            \"anscombe.json\",\n",
      "            \"README.md\",\n",
      "            \"california_housing_train.csv\",\n",
      "            \"mnist_train_small.csv\",\n",
      "            \"california_housing_test.csv\",\n",
      "            \"mnist_test.csv\"\n",
      "        ]\n",
      "    },\n",
      "    \"/data\": {\n",
      "        \"folders\": [],\n",
      "        \"files\": [\n",
      "            \"california_housing_train.csv [[california_housing_train.csv]]\",\n",
      "            \"california_housing_test.csv [[california_housing_test.csv]]\",\n",
      "            \"mnist_train_small.csv [[mnist_train_small.csv]]\",\n",
      "            \"mnist_test.csv [[mnist_test.csv]]\"\n",
      "        ]\n",
      "    },\n",
      "    \"/data/metadata\": {\n",
      "        \"folders\": [],\n",
      "        \"files\": [\n",
      "            \"anscombe.json [[anscombe.json]]\"\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "```\n",
      "'```json\\n{\\n    \"/content\": {\\n        \"folders\": [],\\n        \"files\": [\\n            \"anscombe.json\",\\n            \"README.md\",\\n            \"california_housing_train.csv\",\\n            \"mnist_train_small.csv\",\\n            \"california_housing_test.csv\",\\n            \"mnist_test.csv\"\\n        ]\\n    },\\n    \"/data\": {\\n        \"folders\": [],\\n        \"files\": [\\n            \"california_housing_train.csv [[california_housing_train.csv]]\",\\n            \"california_housing_test.csv [[california_housing_test.csv]]\",\\n            \"mnist_train_small.csv [[mnist_train_small.csv]]\",\\n            \"mnist_test.csv [[mnist_test.csv]]\"\\n        ]\\n    },\\n    \"/data/metadata\": {\\n        \"folders\": [],\\n        \"files\": [\\n            \"anscombe.json [[anscombe.json]]\"\\n        ]\\n    }\\n}\\n```'\n",
      "output break\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def revised_directory():\n",
    "\n",
    "  home_path = os.getcwd()\n",
    "  base_name = os.path.basename(home_path)\n",
    "  tree_file = \"directory_\" + base_name + '.json'\n",
    "  client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "  with open(tree_file, 'r') as newfile:\n",
    "    directory_tree_file = json.load(newfile)\n",
    "    directory_dump = json.dumps(directory_tree_file)\n",
    "\n",
    "  print(directory_tree_file)\n",
    "\n",
    "  prompt = f\"\"\"\n",
    "             Review the given Directory tree json directory tree and return an improved tree based on the following criteria:\n",
    "             1. Kedro Organization standards\n",
    "             2. Kedro Naming standards\n",
    "             3. If applicable, Packaging standards\n",
    "             The Output should be the following\n",
    "             1. Return only valid JSON\n",
    "             2. Contain an improved directory tree with files and directories allowed to be renamed for proper formatting however the previous name must also be present in double brackets\n",
    "             3. The format should follow the structure of the example format:\n",
    "             example format:\n",
    "             '{{\n",
    "                 \"/directory\": {{\n",
    "                     \"folders\": [\n",
    "                      \"/folder1\",\n",
    "                      \"/folder2\"\n",
    "                     ],\n",
    "                     \"files\": [\n",
    "                         \"file.json\",\n",
    "                         \"file.csv\"\n",
    "                         \"README.md\",\n",
    "                         \"file.csv\"\n",
    "                         ]\n",
    "                     }}\n",
    "             }}'\n",
    "\n",
    "            '''\n",
    "            {directory_tree_file}\n",
    "            '''\n",
    "\n",
    "          \"\"\"\n",
    "  try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                      {'role' : 'system', 'content' : 'You are a Data pipeline engineer designing a repository, dont be verbose'},\n",
    "                      {\"role\": \"user\", \"content\": prompt}\n",
    "                     ],\n",
    "            max_tokens=500\n",
    "        )\n",
    "        output = response.choices[0].message.content\n",
    "\n",
    "        print(output)\n",
    "        print(repr(output))\n",
    "        print('output break')\n",
    "        clean_output = output.strip()\n",
    "\n",
    "        match = re.search(r'(\\{.*\\})', clean_output, re.DOTALL)\n",
    "        if match:\n",
    "            clean_json_str = match.group(1)\n",
    "        else:\n",
    "            raise ValueError(\"No valid JSON object found in the API output.\")\n",
    "\n",
    "        parsed_json0 = json.loads(clean_json_str)\n",
    "        # Save to JSON file\n",
    "        with open(f'revised_{base_name}.json', 'w') as json_file:\n",
    "            json.dump(parsed_json0, json_file, indent=4)\n",
    "\n",
    "  except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "revised_directory()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
